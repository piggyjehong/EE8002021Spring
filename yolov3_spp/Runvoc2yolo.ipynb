{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1e5abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "本脚本有两个功能：\n",
    "1.将voc数据集标注信息(.xml)转为yolo标注格式(.txt)，并将图像文件复制到相应文件夹\n",
    "2.根据json标签文件，生成对应names标签(my_data_label.names)\n",
    "\"\"\"\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from lxml import etree\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "\n",
    "# voc数据集根目录以及版本\n",
    "voc_root = \"/Users/wuweizhu/Desktop/VOCdevkit\"\n",
    "voc_version = \"VOC2007\"\n",
    "\n",
    "# 转换的训练集以及验证集对应txt文件\n",
    "train_txt = \"train.txt\"\n",
    "val_txt = \"val.txt\"\n",
    "\n",
    "# 转换后的文件保存目录\n",
    "save_file_root = \"/Users/wuweizhu/Desktop/my_yolo_dataset\"\n",
    "\n",
    "# label标签对应json文件\n",
    "label_json_path = '/Users/wuweizhu/Desktop/deep-learning-for-image-processing/pytorch_object_detection/yolov3_spp/data/pascal_voc_classes.json'\n",
    "\n",
    "# 拼接出voc的images目录，xml目录，txt目录\n",
    "voc_images_path = os.path.join(voc_root, voc_version, \"JPEGImages\")\n",
    "voc_xml_path = os.path.join(voc_root, voc_version, \"Annotations\")\n",
    "train_txt_path = os.path.join(voc_root, voc_version, \"ImageSets\", \"Main\", train_txt)\n",
    "val_txt_path = os.path.join(voc_root, voc_version, \"ImageSets\", \"Main\", val_txt)\n",
    "\n",
    "# 检查文件/文件夹都是否存在\n",
    "assert os.path.exists(voc_images_path), \"VOC images path not exist...\"\n",
    "assert os.path.exists(voc_xml_path), \"VOC xml path not exist...\"\n",
    "assert os.path.exists(train_txt_path), \"VOC train txt file not exist...\"\n",
    "assert os.path.exists(val_txt_path), \"VOC val txt file not exist...\"\n",
    "assert os.path.exists(label_json_path), \"label_json_path does not exist...\"\n",
    "if os.path.exists(save_file_root) is False:\n",
    "    os.makedirs(save_file_root)\n",
    "\n",
    "\n",
    "def parse_xml_to_dict(xml):\n",
    "    \"\"\"\n",
    "    将xml文件解析成字典形式，参考tensorflow的recursive_parse_xml_to_dict\n",
    "    Args：\n",
    "        xml: xml tree obtained by parsing XML file contents using lxml.etree\n",
    "\n",
    "    Returns:\n",
    "        Python dictionary holding XML contents.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(xml) == 0:  # 遍历到底层，直接返回tag对应的信息\n",
    "        return {xml.tag: xml.text}\n",
    "\n",
    "    result = {}\n",
    "    for child in xml:\n",
    "        child_result = parse_xml_to_dict(child)  # 递归遍历标签信息\n",
    "        if child.tag != 'object':\n",
    "            result[child.tag] = child_result[child.tag]\n",
    "        else:\n",
    "            if child.tag not in result:  # 因为object可能有多个，所以需要放入列表里\n",
    "                result[child.tag] = []\n",
    "            result[child.tag].append(child_result[child.tag])\n",
    "    return {xml.tag: result}\n",
    "\n",
    "\n",
    "def translate_info(file_names: list, save_root: str, class_dict: dict, train_val='train'):\n",
    "    \"\"\"\n",
    "    将对应xml文件信息转为yolo中使用的txt文件信息\n",
    "    :param file_names:\n",
    "    :param save_root:\n",
    "    :param class_dict:\n",
    "    :param train_val:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    save_txt_path = os.path.join(save_root, train_val, \"labels\")\n",
    "    if os.path.exists(save_txt_path) is False:\n",
    "        os.makedirs(save_txt_path)\n",
    "    save_images_path = os.path.join(save_root, train_val, \"images\")\n",
    "    if os.path.exists(save_images_path) is False:\n",
    "        os.makedirs(save_images_path)\n",
    "\n",
    "    for file in tqdm(file_names, desc=\"translate {} file...\".format(train_val)):\n",
    "        # 检查下图像文件是否存在\n",
    "        img_path = os.path.join(voc_images_path, file + \".png\")\n",
    "        assert os.path.exists(img_path), \"file:{} not exist...\".format(img_path)\n",
    "\n",
    "        # 检查xml文件是否存在\n",
    "        xml_path = os.path.join(voc_xml_path, file + \".xml\")\n",
    "        assert os.path.exists(xml_path), \"file:{} not exist...\".format(xml_path)\n",
    "\n",
    "        # read xml\n",
    "        with open(xml_path) as fid:\n",
    "            xml_str = fid.read()\n",
    "        xml = etree.fromstring(xml_str)\n",
    "        data = parse_xml_to_dict(xml)[\"annotation\"]\n",
    "        img_height = int(data[\"size\"][\"height\"])\n",
    "        img_width = int(data[\"size\"][\"width\"])\n",
    "\n",
    "        # write object info into txt\n",
    "        with open(os.path.join(save_txt_path, file + \".txt\"), \"w\") as f:\n",
    "            assert \"object\" in data.keys(), \"file: '{}' lack of object key.\".format(xml_path)\n",
    "            for index, obj in enumerate(data[\"object\"]):\n",
    "                # 获取每个object的box信息\n",
    "                xmin = float(obj[\"bndbox\"][\"xmin\"])\n",
    "                xmax = float(obj[\"bndbox\"][\"xmax\"])\n",
    "                ymin = float(obj[\"bndbox\"][\"ymin\"])\n",
    "                ymax = float(obj[\"bndbox\"][\"ymax\"])\n",
    "                class_name = obj[\"name\"]\n",
    "                class_index = class_dict[class_name] - 1  # 目标id从0开始\n",
    "\n",
    "                # 将box信息转换到yolo格式\n",
    "                xcenter = xmin + (xmax - xmin) / 2\n",
    "                ycenter = ymin + (ymax - ymin) / 2\n",
    "                w = xmax - xmin\n",
    "                h = ymax - ymin\n",
    "\n",
    "                # 绝对坐标转相对坐标，保存6位小数\n",
    "                xcenter = round(xcenter / img_width, 6)\n",
    "                ycenter = round(ycenter / img_height, 6)\n",
    "                w = round(w / img_width, 6)\n",
    "                h = round(h / img_height, 6)\n",
    "\n",
    "                info = [str(i) for i in [class_index, xcenter, ycenter, w, h]]\n",
    "\n",
    "                if index == 0:\n",
    "                    f.write(\" \".join(info))\n",
    "                else:\n",
    "                    f.write(\"\\n\" + \" \".join(info))\n",
    "\n",
    "        # copy image into save_images_path\n",
    "        shutil.copyfile(img_path, os.path.join(save_images_path, img_path.split(os.sep)[-1]))\n",
    "\n",
    "\n",
    "def create_class_names(class_dict: dict):\n",
    "    keys = class_dict.keys()\n",
    "    with open(\"./data/my_data_label.names\", \"w\") as w:\n",
    "        for index, k in enumerate(keys):\n",
    "            if index + 1 == len(keys):\n",
    "                w.write(k)\n",
    "            else:\n",
    "                w.write(k + \"\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # read class_indict\n",
    "    json_file = open(label_json_path, 'r')\n",
    "    class_dict = json.load(json_file)\n",
    "\n",
    "    # 读取train.txt中的所有行信息，删除空行\n",
    "    with open(train_txt_path, \"r\") as r:\n",
    "        train_file_names = [i for i in r.read().splitlines() if len(i.strip()) > 0]\n",
    "    # voc信息转yolo，并将图像文件复制到相应文件夹\n",
    "    translate_info(train_file_names, save_file_root, class_dict, \"train\")\n",
    "\n",
    "    # 读取val.txt中的所有行信息，删除空行\n",
    "    with open(val_txt_path, \"r\") as r:\n",
    "        val_file_names = [i for i in r.read().splitlines() if len(i.strip()) > 0]\n",
    "    # voc信息转yolo，并将图像文件复制到相应文件夹\n",
    "    translate_info(val_file_names, save_file_root, class_dict, \"val\")\n",
    "\n",
    "    # 创建my_data_label.names文件\n",
    "    create_class_names(class_dict)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bba9c32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "translate train file...: 100%|██████████| 590/590 [00:01<00:00, 429.32it/s]\n",
      "translate val file...: 100%|██████████| 148/148 [00:00<00:00, 479.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# voc数据集根目录以及版本\n",
    "voc_root = \"/Users/wuweizhu/Desktop/VOCdevkit\"\n",
    "voc_version = \"VOC2007\"\n",
    "\n",
    "# 转换的训练集以及验证集对应txt文件\n",
    "train_txt = \"train.txt\"\n",
    "val_txt = \"val.txt\"\n",
    "\n",
    "# 转换后的文件保存目录\n",
    "save_file_root = \"/Users/wuweizhu/Desktop/my_yolo_dataset\"\n",
    "\n",
    "# label标签对应json文件\n",
    "label_json_path = '/Users/wuweizhu/Desktop/deep-learning-for-image-processing/pytorch_object_detection/yolov3_spp/data/pascal_voc_classes.json'\n",
    "\n",
    "# 拼接出voc的images目录，xml目录，txt目录\n",
    "voc_images_path = os.path.join(voc_root, voc_version, \"JPEGImages\")\n",
    "voc_xml_path = os.path.join(voc_root, voc_version, \"Annotations\")\n",
    "train_txt_path = os.path.join(voc_root, voc_version, \"ImageSets\", \"Main\", train_txt)\n",
    "val_txt_path = os.path.join(voc_root, voc_version, \"ImageSets\", \"Main\", val_txt)\n",
    "\n",
    "# 检查文件/文件夹都是否存在\n",
    "assert os.path.exists(voc_images_path), \"VOC images path not exist...\"\n",
    "assert os.path.exists(voc_xml_path), \"VOC xml path not exist...\"\n",
    "assert os.path.exists(train_txt_path), \"VOC train txt file not exist...\"\n",
    "assert os.path.exists(val_txt_path), \"VOC val txt file not exist...\"\n",
    "assert os.path.exists(label_json_path), \"label_json_path does not exist...\"\n",
    "if os.path.exists(save_file_root) is False:\n",
    "    os.makedirs(save_file_root)\n",
    "\n",
    "\n",
    "def parse_xml_to_dict(xml):\n",
    "    \"\"\"\n",
    "    将xml文件解析成字典形式，参考tensorflow的recursive_parse_xml_to_dict\n",
    "    Args：\n",
    "        xml: xml tree obtained by parsing XML file contents using lxml.etree\n",
    "\n",
    "    Returns:\n",
    "        Python dictionary holding XML contents.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(xml) == 0:  # 遍历到底层，直接返回tag对应的信息\n",
    "        return {xml.tag: xml.text}\n",
    "\n",
    "    result = {}\n",
    "    for child in xml:\n",
    "        child_result = parse_xml_to_dict(child)  # 递归遍历标签信息\n",
    "        if child.tag != 'object':\n",
    "            result[child.tag] = child_result[child.tag]\n",
    "        else:\n",
    "            if child.tag not in result:  # 因为object可能有多个，所以需要放入列表里\n",
    "                result[child.tag] = []\n",
    "            result[child.tag].append(child_result[child.tag])\n",
    "    return {xml.tag: result}\n",
    "\n",
    "\n",
    "def translate_info(file_names: list, save_root: str, class_dict: dict, train_val='train'):\n",
    "    \"\"\"\n",
    "    将对应xml文件信息转为yolo中使用的txt文件信息\n",
    "    :param file_names:\n",
    "    :param save_root:\n",
    "    :param class_dict:\n",
    "    :param train_val:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    save_txt_path = os.path.join(save_root, train_val, \"labels\")\n",
    "    if os.path.exists(save_txt_path) is False:\n",
    "        os.makedirs(save_txt_path)\n",
    "    save_images_path = os.path.join(save_root, train_val, \"images\")\n",
    "    if os.path.exists(save_images_path) is False:\n",
    "        os.makedirs(save_images_path)\n",
    "\n",
    "    for file in tqdm(file_names, desc=\"translate {} file...\".format(train_val)):\n",
    "        # 检查下图像文件是否存在\n",
    "        img_path = os.path.join(voc_images_path, file + \".jpg\")\n",
    "        assert os.path.exists(img_path), \"file:{} not exist...\".format(img_path)\n",
    "\n",
    "        # 检查xml文件是否存在\n",
    "        xml_path = os.path.join(voc_xml_path, file + \".xml\")\n",
    "        assert os.path.exists(xml_path), \"file:{} not exist...\".format(xml_path)\n",
    "\n",
    "        # read xml\n",
    "        with open(xml_path) as fid:\n",
    "            xml_str = fid.read()\n",
    "        xml = etree.fromstring(xml_str)\n",
    "        data = parse_xml_to_dict(xml)[\"annotation\"]\n",
    "        img_height = int(data[\"size\"][\"height\"])\n",
    "        img_width = int(data[\"size\"][\"width\"])\n",
    "\n",
    "        # write object info into txt\n",
    "        with open(os.path.join(save_txt_path, file + \".txt\"), \"w\") as f:\n",
    "            assert \"object\" in data.keys(), \"file: '{}' lack of object key.\".format(xml_path)\n",
    "            for index, obj in enumerate(data[\"object\"]):\n",
    "                # 获取每个object的box信息\n",
    "                xmin = float(obj[\"bndbox\"][\"xmin\"])\n",
    "                xmax = float(obj[\"bndbox\"][\"xmax\"])\n",
    "                ymin = float(obj[\"bndbox\"][\"ymin\"])\n",
    "                ymax = float(obj[\"bndbox\"][\"ymax\"])\n",
    "                class_name = obj[\"name\"]\n",
    "                class_index = class_dict[class_name] - 1  # 目标id从0开始\n",
    "\n",
    "                # 将box信息转换到yolo格式\n",
    "                xcenter = xmin + (xmax - xmin) / 2\n",
    "                ycenter = ymin + (ymax - ymin) / 2\n",
    "                w = xmax - xmin\n",
    "                h = ymax - ymin\n",
    "\n",
    "                # 绝对坐标转相对坐标，保存6位小数\n",
    "                xcenter = round(xcenter / img_width, 6)\n",
    "                ycenter = round(ycenter / img_height, 6)\n",
    "                w = round(w / img_width, 6)\n",
    "                h = round(h / img_height, 6)\n",
    "\n",
    "                info = [str(i) for i in [class_index, xcenter, ycenter, w, h]]\n",
    "\n",
    "                if index == 0:\n",
    "                    f.write(\" \".join(info))\n",
    "                else:\n",
    "                    f.write(\"\\n\" + \" \".join(info))\n",
    "\n",
    "        # copy image into save_images_path\n",
    "        shutil.copyfile(img_path, os.path.join(save_images_path, img_path.split(os.sep)[-1]))\n",
    "\n",
    "\n",
    "def create_class_names(class_dict: dict):\n",
    "    keys = class_dict.keys()\n",
    "    with open(\"./data/my_data_label.names\", \"w\") as w:\n",
    "        for index, k in enumerate(keys):\n",
    "            if index + 1 == len(keys):\n",
    "                w.write(k)\n",
    "            else:\n",
    "                w.write(k + \"\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # read class_indict\n",
    "    json_file = open(label_json_path, 'r')\n",
    "    class_dict = json.load(json_file)\n",
    "\n",
    "    # 读取train.txt中的所有行信息，删除空行\n",
    "    with open(train_txt_path, \"r\") as r:\n",
    "        train_file_names = [i for i in r.read().splitlines() if len(i.strip()) > 0]\n",
    "    # voc信息转yolo，并将图像文件复制到相应文件夹\n",
    "    translate_info(train_file_names, save_file_root, class_dict, \"train\")\n",
    "\n",
    "    # 读取val.txt中的所有行信息，删除空行\n",
    "    with open(val_txt_path, \"r\") as r:\n",
    "        val_file_names = [i for i in r.read().splitlines() if len(i.strip()) > 0]\n",
    "    # voc信息转yolo，并将图像文件复制到相应文件夹\n",
    "    translate_info(val_file_names, save_file_root, class_dict, \"val\")\n",
    "\n",
    "    # 创建my_data_label.names文件\n",
    "    create_class_names(class_dict)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f67968e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
